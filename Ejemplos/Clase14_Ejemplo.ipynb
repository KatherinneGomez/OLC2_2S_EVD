{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Clase 14 - Representación vectorial del texto y modelos clásicos\n",
        "## ¿Por qué vectorizar el texto?\n",
        "\n",
        "Los algoritmos de Machine Learning no entienden texto directamente.\n",
        "Por ello, el texto debe convertirse en vectores numéricos que capturen información semántica o estadística.\n"
      ],
      "metadata": {
        "id": "pwJoof74_seE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bag of Words (BoW)\n",
        "El modelo Bolsa de Palabras representa un texto como un vector de conteos de palabras, ignorando el orden."
      ],
      "metadata": {
        "id": "YjivH1AZ__jt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeUxO8tB-vKc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d08ec031-73b2-44a8-c82a-31c14fa14c26"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              "        [1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0],\n",
              "        [0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1]]),\n",
              " array(['complejo', 'de', 'el', 'es', 'interesante', 'juntos', 'learning',\n",
              "        'lenguaje', 'machine', 'natural', 'nlp', 'procesamiento',\n",
              "        'trabajn'], dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = [\n",
        "    'el nlp es interesante',\n",
        "    'el procesamiento de lenguaje natural es complejo',\n",
        "    'nlp y machine learning trabajn juntos'\n",
        "]\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "x = vectorizer.fit_transform(corpus)\n",
        "\n",
        "x.toarray(), vectorizer.get_feature_names_out()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF (Term Frequency – Inverse Document Frequency)\n",
        "TF-IDF pondera palabras según:\n",
        "\n",
        "* frecuencia en el documento\n",
        "* rareza en el corpus\n",
        "* Reduce el peso de palabras comunes y resalta términos importantes."
      ],
      "metadata": {
        "id": "ycgQGzosAFIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "x = vectorizer.fit_transform(corpus)\n",
        "\n",
        "x.toarray(), vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "dzjGdprrASah",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf690731-db58-421e-a216-d51b8768d31f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.        , 0.        , 0.45985353, 0.45985353, 0.60465213,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.45985353, 0.        , 0.        ],\n",
              "        [0.40301621, 0.40301621, 0.30650422, 0.30650422, 0.        ,\n",
              "         0.        , 0.        , 0.40301621, 0.        , 0.40301621,\n",
              "         0.        , 0.40301621, 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.46735098, 0.46735098, 0.        , 0.46735098, 0.        ,\n",
              "         0.35543247, 0.        , 0.46735098]]),\n",
              " array(['complejo', 'de', 'el', 'es', 'interesante', 'juntos', 'learning',\n",
              "        'lenguaje', 'machine', 'natural', 'nlp', 'procesamiento',\n",
              "        'trabajn'], dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## N-grams\n",
        "Los n-gramas capturan secuencias de palabras consecutivas.\n",
        "\n",
        "\n",
        "```\n",
        "bigrama: machine learning\n",
        "\n",
        "trigrama: procesamiento de lenguaje natural\n",
        "```\n"
      ],
      "metadata": {
        "id": "LyKm2VzPAchs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
        "x = vectorizer.fit_transform(corpus)\n",
        "\n",
        "vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "8toC9gSoAbyA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d3f16d7-d5c2-46c5-de62-c308fa536a3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['complejo', 'de', 'de lenguaje', 'el', 'el nlp',\n",
              "       'el procesamiento', 'es', 'es complejo', 'es interesante',\n",
              "       'interesante', 'juntos', 'learning', 'learning trabajn',\n",
              "       'lenguaje', 'lenguaje natural', 'machine', 'machine learning',\n",
              "       'natural', 'natural es', 'nlp', 'nlp es', 'nlp machine',\n",
              "       'procesamiento', 'procesamiento de', 'trabajn', 'trabajn juntos'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelos Clásicos para NLP\n",
        "\n",
        "Una vez vectorizado el texto, se pueden entrenar modelos de ML tradicionales.\n",
        "\n",
        "**Clasificador de Texto**"
      ],
      "metadata": {
        "id": "OI_FVUN8Aygn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "textos = [\n",
        "    'me encanta este producto',\n",
        "    'odio este producto',\n",
        "    'muy buen servicio',\n",
        "    'lo recomiendo',\n",
        "    'nunca volveré a comprar aquí'\n",
        "]\n",
        "\n",
        "etiquetas = [1, 0, 1, 1, 0]\n",
        "\n",
        "x = TfidfVectorizer().fit_transform(textos)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, etiquetas, test_size=0.2, random_state=42)\n",
        "\n",
        "modelo = MultinomialNB()\n",
        "modelo.fit(x_train, y_train)\n",
        "modelo.predict(x_test)\n",
        "\n",
        "#modelo.score(x_test, y_test)"
      ],
      "metadata": {
        "id": "AYwy4VFKBW5R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07a4f76c-c097-42f0-9153-19bd9a5c80aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qZZ6ieSV2-s",
        "outputId": "e68652e3-a372-46b5-f505-e9dd9d38d2b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Embeddings\n",
        "Los embeddings representan palabras como vectores densos que capturan relaciones semánticas.\n",
        "\n",
        "Ejemplo clásico:\n",
        "\n",
        "`rey - hombre + mujer ≈ reina`"
      ],
      "metadata": {
        "id": "loGtEebsB5As"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download es_core_news_sm"
      ],
      "metadata": {
        "id": "UaXk270DAxoB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6765458-f4c3-4641-8965-4a78179868b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting es-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('es_core_news_sm')\n",
        "\n",
        "doc = nlp('perro tijeras gato veterinario')\n",
        "\n",
        "for token in doc:\n",
        "  print(token.text, token.vector[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmHGc7EQYwdu",
        "outputId": "23dfe37c-41df-407f-f9cb-eb7a29dfaa60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perro [ 0.33787465 -0.529732    1.0501668  -5.0766463   0.3385839 ]\n",
            "tijeras [ 0.37337202  1.3906447  -2.328543   -2.7364414   1.0993222 ]\n",
            "gato [ 3.8799098   0.81480527 -1.454298    0.06635606  2.7632985 ]\n",
            "veterinario [ 0.9434247   1.3979921  -2.0738053  -0.34742498  4.5999537 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = nlp('perro')\n",
        "doc2 = nlp('gato')\n",
        "\n",
        "doc1.similarity(doc2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFXrDsxTZ9o3",
        "outputId": "a22bb9bf-5616-4f90-ddde-d39ce619def9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1399058968.py:4: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  doc1.similarity(doc2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5870431661605835"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ¿Por qué Deep Learning en NLP?\n",
        "\n",
        "Los métodos clásicos (BoW, TF-IDF) no capturan bien:\n",
        "\n",
        "* Contexto\n",
        "* Dependencias largas\n",
        "* Significado semántico profundo"
      ],
      "metadata": {
        "id": "yxCR2YByD5eV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Embeddings con Word2Vec\n",
        "Es un modelo que aprende vectores densos para palabras, donde palabras con significado similar tienen vectores cercanos."
      ],
      "metadata": {
        "id": "L9xmDjPRD-va"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalación de dependencias\n",
        "!pip install gensim"
      ],
      "metadata": {
        "id": "o2vzTXFEEEmP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b67e086a-f174-4850-e4ee-ed86d0e93280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "sentences = [\n",
        "    ['el', 'nlp', 'es', 'interesante'],\n",
        "    ['machine', 'learning', 'y', 'nlp'],\n",
        "    ['deep', 'learning', 'en', 'nlp']\n",
        "]\n",
        "\n",
        "modelo = Word2Vec(sentences, vector_size=50, window=3, min_count=1)\n",
        "\n",
        "modelo.wv['learning'][:10]\n"
      ],
      "metadata": {
        "id": "hmkO99DXEKt-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d65e43a-9afa-410c-dcbd-30ccfa466866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.01631583,  0.0089916 , -0.00827415,  0.00164907,  0.01699724,\n",
              "       -0.00892435,  0.009035  , -0.01357392, -0.00709698,  0.01879702],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aplicaciones\n"
      ],
      "metadata": {
        "id": "97RC1IeSIz-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análisis de sentimientos\n",
        "El análisis de sentimientos busca identificar la carga emocional de un texto:\n",
        "\n",
        "* Positiva\n",
        "* Negativa\n",
        "* Neutral\n",
        "\n",
        "En NLTK, una de las herramientas más usadas es VADER, diseñada para textos cortos y lenguaje natural."
      ],
      "metadata": {
        "id": "BhCCo9PKz1b_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "VADER (Valence Aware Dictionary and sEntiment Reasoner) es:\n",
        "\n",
        "* Un enfoque basado en léxico\n",
        "* No requiere entrenamiento"
      ],
      "metadata": {
        "id": "cBHXrry_z5Kl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "texto = 'I love this product.'\n",
        "\n",
        "# compund >= 0.05 -> positivo\n",
        "# compund <= -0.05 -> negativo\n",
        "# compund  entre 0.05 y -0.05 -> neutro\n",
        "sia.polarity_scores(texto)"
      ],
      "metadata": {
        "id": "fqpklG4g0XfP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b12eeef6-e1b6-4f22-ed21-a8f5d6f17c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.6369}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Named Entity Recognition (NER)\n",
        "Identifica y clasifica entidades con nombre dentro de un texto, como:\n",
        "\n",
        "* Personas\n",
        "* Organizaciones\n",
        "* Fechas\n",
        "* Lugares\n",
        "* Cantidades"
      ],
      "metadata": {
        "id": "CYtf_G3lzvV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download es_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSOlTKhbtz7x",
        "outputId": "ba263d1d-2430-485c-df4f-5da79c22939a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting es-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('es_core_news_sm')\n",
        "\n",
        "texto = 'Microsoft proporciona un excelente servicio, fue fundada en 1979 en Nuevo Mexico, Estados Unidos'\n",
        "doc = nlp(texto)\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.label_)\n"
      ],
      "metadata": {
        "id": "bk1grRhPI9Xe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79565867-6c52-48d0-e8fd-cc6f5f01e209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Microsoft ORG\n",
            "Nuevo Mexico LOC\n",
            "Estados Unidos LOC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp2 = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = 'Microsoft was founded in 1975 by Bill Gates and Paul Allen to revolutionize personal computing.'\n",
        "doc = nlp2(text)\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtYVWx15vQ8V",
        "outputId": "2cd0baba-d89d-4fba-9dca-988332f18d01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Microsoft ORG\n",
            "1975 DATE\n",
            "Bill Gates PERSON\n",
            "Paul Allen PERSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part-of-Speech Tagging (POS)\n",
        "\n",
        "Asigna a cada palabra su categoría gramatical:\n",
        "\n",
        "* Sustantivo\n",
        "* Verbo\n",
        "* Adjetivo\n",
        "* Adverbio, etc.\n",
        "\n",
        "Es clave para:\n",
        "* análisis sintáctico\n",
        "* extracción de información\n",
        "* traducción automática"
      ],
      "metadata": {
        "id": "2EsZC7GBJVrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "pos_tags = pos_tag(tokens)\n",
        "\n",
        "pos_tags"
      ],
      "metadata": {
        "id": "CjhiCr87JEq_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "481e76dd-dd83-4b3c-cc09-7904c947d18e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Microsoft', 'NNP'),\n",
              " ('was', 'VBD'),\n",
              " ('founded', 'VBN'),\n",
              " ('in', 'IN'),\n",
              " ('1975', 'CD'),\n",
              " ('by', 'IN'),\n",
              " ('Bill', 'NNP'),\n",
              " ('Gates', 'NNP'),\n",
              " ('and', 'CC'),\n",
              " ('Paul', 'NNP'),\n",
              " ('Allen', 'NNP'),\n",
              " ('to', 'TO'),\n",
              " ('revolutionize', 'VB'),\n",
              " ('personal', 'JJ'),\n",
              " ('computing', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}